---
title: Patchscope
path: daimafuzhu/patchscope
description: >-
  Patchscope是一个用于检查大型语言模型（LLM）隐藏表示的统一框架。它能解释模型行为，验证其与人类价值观的一致性。通过利用模型本身生成人类可理解的文本，我们提出利用模型本身来解释其自然语言内部表示。我们展示了Patchscopes框架如何用于回答关于LLM计算的广泛研究问题。我们发现，基于将表示投影到词汇空间和干预LLM计算的先前可解释性方法，可以被视为此框架的特殊实例。此外，Patchscope还开辟了新的可能性，例如使用更强大的模型来解释较小模型的表示，并解锁了自我纠正等新应用，如多跳推理。
source: ''
cover: /cover/20240612/6/12/20240612_b4558b22.jpg
logo: /logo/20240612/6/12/20240612_ebdc2b5f.jpg
label: 语言模型隐藏表示检查统一框架
component: false
procattr: 5
procattrname: 编程
procform: 6
procformname: 其他
proctype: 1
proctypename: 普通产品
tags:
  - 语言模型
  - 可解释性
  - 编程
createTime: '2024-01-12 10:54:52'
updateTime: '2024-01-12 10:54:52'
lang: en
isicp: 2
isqian: 1
iswx: 2
isqq: 2
iscom: 2
price: ''
catname: 编程
sort: 27061
---



### 需求人群
Patchscope可用于研究大型语言模型的内部工作原理，验证其与人类价值观的一致性，以及回答关于LLM计算的研究问题。

### 产品特色
- 解释大型语言模型的内部表示
- 验证模型与人类价值观的一致性
- 回答关于LLM计算的研究问题

### 使用场景示例
- 用于分析大型语言模型生成的文本
- 验证语言模型是否符合特定价值观
- 研究语言模型计算的内部表示

### 使用教程


  
