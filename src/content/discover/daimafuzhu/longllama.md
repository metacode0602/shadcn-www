---
title: LongLLaMA
path: daimafuzhu/longllama
description: >-
  LongLLaMA 是一个大型语言模型，能够处理长篇文本。它基于 OpenLLaMA，并使用 Focused Transformer (FoT)
  方法进行了微调。它能够处理长达 256k 标记甚至更多的文本。我们提供了一个较小的 3B 基础模型（未经过指令调整），并在 Hugging Face
  上提供了支持更长上下文的推断代码。我们的模型权重可以作为现有实现中 LLaMA 的替代品（适用于最多 2048
  个标记的短上下文）。此外，我们还提供了评估结果和与原始 OpenLLaMA 模型的比较。
source: 'https://github.com/CStanKonrad/long_llama'
cover: /cover/20240612/6/12/20240612_8dd46fb1.jpg
logo: /logo/20240612/6/12/20240612_92554964.jpg
label: 处理长文本的大型语言模型
component: false
procattr: 5
procattrname: 编程
procform: 5
procformname: 模型
proctype: 1
proctypename: 普通产品
tags:
  - 语言模型
  - 自然语言处理
  - 开发编程
createTime: '2023-09-25 08:49:41'
updateTime: '2023-09-25 08:49:41'
lang: en
isicp: 2
isqian: 2
iswx: 2
isqq: 2
iscom: 2
price: ''
catname: 自然语言处理
sort: 13341
---



### 需求人群
适用于各种自然语言处理任务，如文本生成、文本分类、问答系统等

### 产品特色
- 处理长篇文本
- 支持 256k 标记或更长的文本
- 用于自然语言处理任务

### 使用场景示例


### 使用教程


  
