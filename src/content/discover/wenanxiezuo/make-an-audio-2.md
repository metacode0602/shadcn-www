---
title: Make-An-Audio 2
path: wenanxiezuo/make-an-audio-2
description: >-
  Make-An-Audio
  2是一种基于扩散模型的文本到音频生成技术，由浙江大学、字节跳动和香港中文大学的研究人员共同开发。该技术通过使用预训练的大型语言模型(LLMs)解析文本，优化了语义对齐和时间一致性，提高了生成音频的质量。它还设计了基于前馈Transformer的扩散去噪器，以改善变长音频生成的性能，并增强时间信息的提取。此外，通过使用LLMs将大量音频标签数据转换为音频文本数据集，解决了时间数据稀缺的问题。
source: 'https://make-an-audio-2.github.io/'
cover: /cover/20240609/6/9/20240609_5724568e.jpg
logo: /logo/20240609/6/9/20240609_68656170.jpg
label: 基于扩散模型的文本到音频生成技术
component: false
procattr: 14
procattrname: 其他
procform: 5
procformname: 模型
proctype: 1
proctypename: 普通产品
tags:
  - 文本到音频
  - 扩散模型
  - 大型语言模型
  - 音频合成
createTime: '2024-05-27 11:42:49'
updateTime: '2024-05-27 11:42:49'
lang: en
isicp: 2
isqian: 2
iswx: 2
isqq: 2
iscom: 2
price: 免费
---



## 需求人群
"该技术的目标受众是音频合成领域的研究人员和开发者，以及需要高质量文本到音频转换的应用场景，如自动配音、有声读物制作等。Make-An-Audio 2通过其先进的技术，能够生成与文本内容语义对齐且时间一致的高质量音频，满足这些用户的需求。"

## 产品特色
* 使用预训练的大型语言模型(LLMs)解析文本，优化时间信息捕获
* 引入结构化文本编码器，辅助学习扩散去噪过程中的语义对齐
* 设计基于前馈Transformer的扩散去噪器，改善变长音频生成性能
* 利用LLMs增强和转换音频标签数据，缓解时间数据稀缺问题
* 在客观和主观指标上超越基线模型，显著提升时间信息理解、语义一致性和声音质量

## 使用场景示例
* 自动生成有声读物的背景音效和对话
* 为视频内容自动添加旁白和音效
* 创建虚拟角色的声音，用于游戏或动画

## 使用教程
* 步骤1: 准备自然语言文本作为输入
* 步骤2: 使用Make-An-Audio 2的Text Encoder解析文本
* 步骤3: 结构化文本编码器辅助学习语义对齐
* 步骤4: 利用扩散去噪器生成音频
* 步骤5: 调整生成音频的长度和时间控制
* 步骤6: 根据需要修改结构化输入以精确控制时间
* 步骤7: 生成最终的音频输出

  
